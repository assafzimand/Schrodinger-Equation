# Training Configuration
# Deep Learning Approximation of the Schr√∂dinger Equation

train:
  # Training hyperparameters
  epochs: 1000
  learning_rate: 0.0001
  batch_size: 512
  
  # Hardware settings
  device: auto  # Options: 'auto', 'cuda', 'cpu'
  
  # Model architecture
  hidden_layers: 5
  hidden_neurons: 100
  activation: tanh  # Activation function for hidden layers
  
  # Optimizer settings
  optimizer: adam
  
  # Learning rate scheduler (optional)
  scheduler:
    type: null  # Options: 'reduce_on_plateau', 'step', 'cosine', or null for no scheduler
    factor: 0.5  # Factor by which learning rate is reduced (for ReduceLROnPlateau)
    patience: 100  # Number of epochs with no improvement before reducing LR
    cooldown: 50  # Number of epochs to wait before resuming normal operation
    min_lr: 1.0e-7  # Minimum learning rate
    threshold: 1.0e-4  # Threshold for measuring improvement
    threshold_mode: rel  # 'rel' or 'abs'
  
  # Reproducibility
  seed: 42
  dtype: float32  # Options: 'float32', 'float64'
  deterministic: false  # Use deterministic CuDNN (slower but reproducible)
  
  # Experiment tracking
  mlflow_experiment: schrodinger_step1
  checkpoint_dir: outputs/checkpoints
  
  # Pretrained model loading (optional)
  # Uncomment and set one of these to load a pretrained checkpoint:
  # pretrained_run_id: null  # MLflow run ID (e.g., "abc123def456")
  pretrained_checkpoint: "outputs/grid_search_20251110_094116/mlruns/228991845337437334/artifacts/best_model.pt"  # Direct path to checkpoint (e.g., "outputs/checkpoints/best_model.pt")
  resume_training: false  # If true, resume from checkpoint epoch; if false, start from epoch 1
